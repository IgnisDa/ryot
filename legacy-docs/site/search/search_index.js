var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Installation","text":"<p>Use the following docker-compose file:</p> <pre><code>services:\nryot-db:\nimage: postgres:16-alpine # at-least version 15 is required\nrestart: unless-stopped\nvolumes:\n- postgres_storage:/var/lib/postgresql/data\nenvironment:\n- POSTGRES_PASSWORD=postgres\n- POSTGRES_USER=postgres\n- POSTGRES_DB=postgres\n- TZ=Europe/Amsterdam\ncontainer_name: ryot-db\n\nryot:\nimage: ignisda/ryot:v7 # or ghcr.io/ignisda/ryot:v7\nenvironment:\n- DATABASE_URL=postgres://postgres:postgres@ryot-db:5432/postgres\n- TZ=Europe/Amsterdam\n- SERVER_ADMIN_ACCESS_TOKEN=28ebb3ae554fa9867ba0 # CHANGE THIS\nports:\n- \"8000:8000\"\npull_policy: always\ncontainer_name: ryot\n\nvolumes:\npostgres_storage:\n</code></pre> <p>If you would like to run the pro version, please check below. To see the features of the pro version, check the features page.</p>"},{"location":"index.html#upgrading-to-pro","title":"Upgrading to Pro","text":"<p>To upgrade to the pro version, you need to provide a <code>SERVER_PRO_KEY</code> environment variable. You can get a key by purchasing it from the website.</p> <p>Once you have the key, you can set it in the <code>docker-compose.yml</code> file:</p> <pre><code>  ryot:\n    environment:\n+      - SERVER_PRO_KEY=&lt;pro_key_issued_to_you&gt;\n</code></pre> <p>If the key is invalid or your subscription has expired, the server will automatically start with the community version. Since the two versions are compatible, you can switch between them by simply fixing the key and restarting the server.</p>"},{"location":"configuration.html","title":"Configuration","text":"<p>You can specify configuration options via environment variables. Each option is documented below with what it does and a default (if any).</p> <p>Ryot serves the final configuration loaded at the <code>/backend/config</code> endpoint as JSON (example). Sensitive variables are redacted.</p>"},{"location":"configuration.html#important-parameters","title":"Important parameters","text":"Environment variable Description <code>PORT</code> The port to listen on. Defaults to <code>8000</code>. <code>TZ</code> Timezone to be used for cron jobs. Accepts values according to the IANA database. Defaults to <code>GMT</code>. <code>DISABLE_TELEMETRY</code> Disables telemetry collection using Umami. Defaults to <code>false</code>. <code>DATABASE_URL</code> The Postgres database connection string. <code>VIDEO_GAMES_TWITCH_CLIENT_ID</code> The client ID issued by Twitch. Required to enable video games tracking. More information <code>VIDEO_GAMES_TWITCH_CLIENT_SECRET</code> The client secret issued by Twitch. Required to enable video games tracking."},{"location":"configuration.html#health-endpoint","title":"Health endpoint","text":"<p>The <code>/health</code> endpoint can be used for checking service healthiness. More information here.</p>"},{"location":"configuration.html#all-parameters","title":"All parameters","text":"<pre><code># Settings related to anime and manga.\nanime_and_manga:\n# Settings related to Anilist.\nanilist:\n# The preferred language for media from this source.\n# @envvar ANIME_AND_MANGA_ANILIST_PREFERRED_LANGUAGE\npreferred_language: \"native\"\n\n# Settings related to MAL.\nmal:\n# The client ID to be used for the MAL API.\n# @envvar ANIME_AND_MANGA_MAL_CLIENT_ID\nclient_id: \"\"\n\n# Settings related to MangaUpdates.\nmanga_updates: {}\n\n# Settings related to audio books.\naudio_books:\n# Settings related to Audible.\naudible:\n# Settings related to locale for making requests Audible.\n# @envvar AUDIO_BOOKS_AUDIBLE_LOCALE\nlocale: \"us\"\n\n# Settings related to books.\nbooks:\n# Settings related to Google Books.\ngoogle_books:\n# The API key to be used for the Google Books API.\n# @envvar BOOKS_GOOGLE_BOOKS_API_KEY\napi_key: \"\"\n\n# Whether to pass the raw query string to the search API.\n# @envvar BOOKS_GOOGLE_BOOKS_PASS_RAW_QUERY\npass_raw_query: false\n\n# Settings related to Openlibrary.\nopenlibrary:\n# The image sizes to fetch from Openlibrary.\n# @envvar BOOKS_OPENLIBRARY_COVER_IMAGE_SIZE\ncover_image_size: \"M\"\n\n# The database related settings.\ndatabase:\n# The Postgres database connection string.\n# Format described in https://www.sea-ql.org/SeaORM/docs/install-and-config/connection/#postgres.\n# @envvar DATABASE_URL\nurl: \"\"\n\n# Whether to disable telemetry.\n# @envvar DISABLE_TELEMETRY\ndisable_telemetry: false\n\n# Settings related to exercises.\nexercise: {}\n\n# Settings related to file storage.\nfile_storage:\n# The access key ID for the S3 compatible file storage. **Required** to\n# enable file storage.\n# @envvar FILE_STORAGE_S3_ACCESS_KEY_ID\ns3_access_key_id: \"\"\n\n# The name of the S3 compatible bucket. **Required** to enable file storage.\n# @envvar FILE_STORAGE_S3_BUCKET_NAME\ns3_bucket_name: \"\"\n\n# The region for the S3 compatible file storage.\n# @envvar FILE_STORAGE_S3_REGION\ns3_region: \"us-east-1\"\n\n# The secret access key for the S3 compatible file storage. **Required**\n# to enable file storage.\n# @envvar FILE_STORAGE_S3_SECRET_ACCESS_KEY\ns3_secret_access_key: \"\"\n\n# The URL for the S3 compatible file storage.\n# @envvar FILE_STORAGE_S3_URL\ns3_url: \"\"\n\n# Settings related to frontend storage.\nfrontend:\n# A message to be displayed on the dashboard.\n# @envvar FRONTEND_DASHBOARD_MESSAGE\ndashboard_message: \"\"\n\n# The button label for OIDC authentication.\n# @envvar FRONTEND_OIDC_BUTTON_LABEL\noidc_button_label: \"Continue with OpenID Connect\"\n\n# The number of items to display in a list view.\n# @envvar FRONTEND_PAGE_SIZE\npage_size: 20\n\n# Settings related to Umami analytics.\numami:\n# @envvar FRONTEND_UMAMI_DOMAINS\ndomains: \"\"\n\n# For example: https://umami.is/script.js.\n# @envvar FRONTEND_UMAMI_SCRIPT_URL\nscript_url: \"\"\n\n# @envvar FRONTEND_UMAMI_WEBSITE_ID\nwebsite_id: \"\"\n\n# Used as the base URL when generating item links for the frontend.\n# @envvar FRONTEND_URL\nurl: \"https://pro.ryot.io\"\n\n# Settings related to external integrations.\nintegration:\n# Sync data from push and yank based integrations every `n` minutes.\n# @envvar INTEGRATION_SYNC_EVERY_MINUTES\nsync_every_minutes: 5\n\n# Settings related to media.\nmedia:\n# Number of days after which a media should be removed from the Monitoring collection.\n# @envvar MEDIA_MONITORING_REMOVE_AFTER_DAYS\nmonitoring_remove_after_days: 30\n\n# Settings related to movies and shows.\nmovies_and_shows:\n# Settings related to TMDB.\ntmdb:\n# The access token for the TMDB API.\n# @envvar MOVIES_AND_SHOWS_TMDB_ACCESS_TOKEN\naccess_token: \"\"\n\n# The locale to use for making requests to TMDB API.\n# @envvar MOVIES_AND_SHOWS_TMDB_LOCALE\nlocale: \"en\"\n\n# Settings related to podcasts.\npodcasts:\n# Settings related to iTunes.\nitunes:\n# The locale to use for making requests to iTunes API.\n# @envvar PODCASTS_ITUNES_LOCALE\nlocale: \"en_us\"\n\n# Settings related to Listennotes.\nlistennotes:\n# The access token for the Listennotes API.\n# @envvar PODCASTS_LISTENNOTES_API_TOKEN\napi_token: \"\"\n\n# Settings related to scheduler.\nscheduler:\n# The number of jobs to process every 5 seconds when updating metadata in\n# the background.\n# @envvar SCHEDULER_RATE_LIMIT_NUM\nrate_limit_num: 5\n\n# Settings related to server.\nserver:\n# An access token that can be used for admin operations.\n# @envvar SERVER_ADMIN_ACCESS_TOKEN\nadmin_access_token: \"\"\n\n# An array of URLs for CORS.\n# @envvar SERVER_CORS_ORIGINS\ncors_origins: []\n\n# Disable all background jobs.\n# @envvar SERVER_DISABLE_BACKGROUND_JOBS\ndisable_background_jobs: false\n\n# Whether the graphql playground will be enabled.\n# @envvar SERVER_GRAPHQL_PLAYGROUND_ENABLED\ngraphql_playground_enabled: true\n\n# The maximum file size in MB for user uploads.\n# @envvar SERVER_MAX_FILE_SIZE\nmax_file_size: 70\n\n# The OIDC related settings.\noidc:\n# @envvar SERVER_OIDC_CLIENT_ID\nclient_id: \"\"\n\n# @envvar SERVER_OIDC_CLIENT_SECRET\nclient_secret: \"\"\n\n# @envvar SERVER_OIDC_ISSUER_URL\nissuer_url: \"\"\n\n# The pro key assigned to the user.\n# @envvar SERVER_PRO_KEY\npro_key: \"\"\n\n# The hours in which a media can be marked as seen again for a user. This\n# is used so that the same media can not be used marked as started when\n# it has been already marked as seen in the last `n` hours.\n# @envvar SERVER_PROGRESS_UPDATE_THRESHOLD\nprogress_update_threshold: 2\n\n# Number of seconds to sleep before starting the server.\n# @envvar SERVER_SLEEP_BEFORE_STARTUP_SECONDS\nsleep_before_startup_seconds: 0\n\n# The mailer related settings.\nsmtp:\n# @envvar SERVER_SMTP_MAILBOX\nmailbox: \"Ryot &lt;no-reply@mailer.io&gt;\"\n\n# @envvar SERVER_SMTP_PASSWORD\npassword: \"\"\n\n# @envvar SERVER_SMTP_SERVER\nserver: \"\"\n\n# @envvar SERVER_SMTP_USER\nuser: \"\"\n\n# Settings related to users.\nusers:\n# Whether new users will be allowed to sign up to this instance.\n# @envvar USERS_ALLOW_REGISTRATION\nallow_registration: true\n\n# Whether to disable local user authentication completely.\n# @envvar USERS_DISABLE_LOCAL_AUTH\ndisable_local_auth: false\n\n# The secret used for generating JWT tokens.\n# @envvar USERS_JWT_SECRET\njwt_secret: \"\"\n\n# The number of days till login authentication token is valid.\n# @envvar USERS_TOKEN_VALID_FOR_DAYS\ntoken_valid_for_days: 90\n\n# Settings related to video games.\nvideo_games:\n# Settings related to IGDB.\nigdb:\n# The image sizes to fetch from IGDB.\n# @envvar VIDEO_GAMES_IGDB_IMAGE_SIZE\nimage_size: \"t_original\"\n\n# Settings related to Twitch.\ntwitch:\n# The client ID issues by Twitch. **Required** to enable video games\n# tracking. [More information](/docs/guides/video-games.md).\n# @envvar VIDEO_GAMES_TWITCH_CLIENT_ID\nclient_id: \"\"\n\n# The client secret issued by Twitch. **Required** to enable video games\n# tracking.\n# @envvar VIDEO_GAMES_TWITCH_CLIENT_SECRET\nclient_secret: \"\"\n\n# Settings related to visual novels.\nvisual_novels: {}\n</code></pre>"},{"location":"contributing.html","title":"Contributing","text":"<p>Each version of Ryot is released as docker images. For example, if the latest tag is <code>v5.2.1</code>, then the docker image will be tagged as <code>v5.2.1</code>, <code>v5.2</code>, <code>v5</code> and <code>latest</code>. The images will be made available on Docker Hub and GitHub Container Registry.</p>"},{"location":"contributing.html#development","title":"Development","text":"<p>There is a devcontainer configuration in the repository. You can use it to launch a development environment with all tools installed.</p>"},{"location":"contributing.html#environment","title":"Environment","text":"<p>Create the following environment file in the root of the repository:</p> .env<pre><code>DATABASE_URL=postgres://postgres:postgres@postgres:5432/postgres\nUNKEY_API_ID=api_4GvvJVbWobkNjcnnvFHmBP5pXb4K\nAPP_VERSION=v5.2.1\nDEFAULT_TMDB_ACCESS_TOKEN=your-tmdb-access-token\nDEFAULT_MAL_CLIENT_ID=your-mal-client-id\nTRAKT_CLIENT_ID=your-trakt-client-id\n</code></pre> <p>In development, both servers are started independently running on <code>:3000</code> and <code>:5000</code> respectively and reverse proxied at <code>:8000</code>. To get everything started, run <code>mprocs</code> in the project root.</p> <p>Your website would be available at <code>http://localhost:8000</code>.</p>"},{"location":"deployment.html","title":"Deployment","text":"<p>The easiest way to deploy Ryot is using the docker compose. Here is a non-exhaustive set of guides to deploy Ryot to alternative platforms.</p>"},{"location":"deployment.html#railway","title":"Railway","text":"<ol> <li>Click on \"+ New Project\" on your dashboard and select \"Empty project\".</li> <li>Once the project is created click on \"+ New\" and select \"Database\" and then   \"Add PostgreSQL\".</li> <li>Click on \"+ New\" again and select \"Docker Image\". Type <code>ignisda/ryot</code> and hit Enter.</li> <li>Click on the newly created service and go to the \"Variables\" section. Click on   \"New Variable\" and then \"Add Reference\". Click on \"Add\".</li> <li>Go to the \"Settings\" tab and then click on \"Generate Domain\".</li> <li>Optionally, you can set the health-check   path to <code>/health</code>.</li> </ol>"},{"location":"deployment.html#dokku","title":"Dokku","text":"<p>This is a script that automatically sets up a Ryot server using the docker image uploaded to Ghcr and creates a Dokku app. The script assumes you have a global domain set-up (i.e. the file <code>/home/dokku/VHOST</code> exists). It needs to be run with <code>sudo</code> privileges.</p> <p>Re-running it updates the running server to the latest version.</p> <pre><code>#!/usr/bin/env bash\n\nset -euo pipefail\n\nif [ \"$EUID\" -ne 0 ]\nthen echo \"Please run as root\"\nexit\nfi\n\nIMAGE_NAME=\"ignisda/ryot\"\nAPPNAME=\"\"\n\nread -rp \"Enter the name of the app: \" APPNAME\n\n# check if app name is empty\nif [ -z \"$APPNAME\" ]; then\necho \"App name empty. Using default name: ryot\"\nAPPNAME=\"ryot\"\nfi\n\n# pull the latest image\ndocker rmi -f \"$IMAGE_NAME\" || true\ndocker pull \"$IMAGE_NAME:latest\"\nimage_sha=\"$(docker inspect --format=\"{{index .RepoDigests 0}}\" $IMAGE_NAME)\"\necho \"Calculated image sha: $image_sha\"\n\nif dokku apps:exists $APPNAME; then\ndokku git:from-image $APPNAME $image_sha || echo \"Already on latest\"\nexit 0\nfi\n\ndokku apps:create \"$APPNAME\"\ndokku postgres:create \"$APPNAME-service\"\ndokku postgres:link \"$APPNAME-service\" \"$APPNAME\"\n\n# check if required dokku plugin exists\nif ! dokku plugin:list | grep letsencrypt; then\ndokku plugin:install https://github.com/dokku/dokku-letsencrypt.git\nfi\n\ndokku domains:add $APPNAME $APPNAME.\"$(cat /home/dokku/VHOST)\"\ndokku letsencrypt:enable \"$APPNAME\"\ndokku git:from-image \"$APPNAME\" \"$image_sha\"\n</code></pre>"},{"location":"deployment.html#fly","title":"Fly","text":"<p>The demo Ryot instance is deployed to Fly. The following steps are required to deploy to Fly.</p> <ol> <li> <p>Create a new postgres database for Ryot.    <pre><code>flyctl postgres create ryot-db\n</code></pre></p> </li> <li> <p>Copy the <code>fly.toml</code> file from this    repository to your own repository. You WILL have to change the <code>app</code> key to    a unique name. Deploy it using the below command.    <pre><code>flyctl launch\n</code></pre></p> </li> <li> <p>Connect the database.    <pre><code>fly postgres attach --app ryot ryot-db\n</code></pre></p> </li> <li> <p>Optionally you can configure the instance using <code>fly secrets set</code>.    <pre><code>fly secrets set FILE_STORAGE_S3_URL='https://play.min.io:9000'\n</code></pre></p> </li> </ol>"},{"location":"deployment.html#cosmos","title":"Cosmos","text":"<p>You can install <code>ryot</code> from the Cosmos marketplace using this link: Install Ryot or by searching for <code>Ryot</code> in the marketplace.</p> <p>Review the installation summary and click install to proceed. The database and credentials will be automatically created for you, but make sure you are happy with the URL chosen.</p> <p>The instance will be available under your newly created URL via HTTPS if it is enabled. You can then proceed with creating your first user via the web interface's registration page.</p>"},{"location":"importing.html","title":"Importing","text":"<p>Importing is meant to be a one-time operation. They are irreversible, i.e., importing from the same source twice will create duplicates. I recommend you to make a database backup before starting an import.</p> <p>An import can fail at various steps. Ryot creates a report when an import completes/fails. You can see the reports under \"Import History\" of the imports page.</p>"},{"location":"importing.html#notes","title":"Notes","text":"<ul> <li>Imports are very difficult to have 100% success rate. Though we try our best,   you might have to manually import some data from your previous provider.</li> <li>I recommend turning on debug logging for the duration of the import using the   <code>RUST_LOG=ryot=debug</code> environment variable. This will help you help you see import   progress in the docker logs.</li> </ul>"},{"location":"importing.html#goodreads","title":"Goodreads","text":"<p>Ryot translates Goodreads shelves in the following manner:</p> <ul> <li>Want To Read -&gt; Watchlist</li> </ul>"},{"location":"importing.html#steps","title":"Steps","text":"<ul> <li>Login to your Goodreads account and go to the \"My Books\" section.</li> <li>Click on \"Import and export\" on the left sidebar.</li> <li>Click on \"Export Library\" and download the CSV file.</li> <li>Upload this file in the input.</li> </ul>"},{"location":"importing.html#mediatracker","title":"MediaTracker","text":"<p>You can import from MediaTracker, with the following caveats:</p> <ul> <li>Items that are in progress are always imported with 100% progress. They are   added to the \"In Progress\" collection so you can manually fix their progress   if needed.</li> </ul>"},{"location":"importing.html#steps_1","title":"Steps","text":"<ul> <li>Login to your MediaTracker account and click on your name on the top right.</li> <li>Click on the \"Application tokens\" section.</li> <li>Enter a name and click on \"Add token\".</li> <li>Copy the token that was just generated.</li> <li>Enter the details in the inputs.</li> </ul>"},{"location":"importing.html#movary","title":"Movary","text":"<p>The Watchlist and all movies can be imported from Movary along with ratings, history, and comments.</p>"},{"location":"importing.html#steps_2","title":"Steps","text":"<ul> <li>Login to your Movary account and go to the settings page. Go to \"Personal data\"   under the \"Account\" section.</li> <li>Export \"history.csv\", \"watchlist.csv\" and \"ratings.csv\".</li> <li>Upload these files in the input.</li> </ul>"},{"location":"importing.html#myanimelist","title":"MyAnimeList","text":"<p>Manga and Anime can be imported from MyAnimeList along with ratings, history and progress.</p>"},{"location":"importing.html#steps_3","title":"Steps","text":"<ul> <li>Login to your MyAnimeList account and go to   exports.</li> <li>Export your anime and manga history.</li> <li>Upload these files in the input.</li> </ul>"},{"location":"importing.html#storygraph","title":"StoryGraph","text":"<p>Imports from StoryGraph work using ISBN. All books in your export that have an ISBN attached to them will be imported. Ryot translates \"Read Status\" in the following manner:</p> <ul> <li>to-read -&gt; Watchlist</li> </ul>"},{"location":"importing.html#steps_4","title":"Steps","text":"<ul> <li>Login to your account and click on your profile and go to the \"Manage Account\"   page.</li> <li>Scroll to the bottom and click on \"Export StoryGraph Library\" and then   \"Generate export\".</li> <li>Once the export is done, you will receive an email. refresh the page above and   download the CSV file.</li> <li>Optionally, you can edit the CSV file and manually add the missing ISBN.</li> <li>Upload this file in the input.</li> </ul>"},{"location":"importing.html#strong-app","title":"Strong App","text":"<p>You can import your completed workouts from Strong app. Make sure you do the import process on a desktop/laptop since the process needs to have multiple tabs open at once.</p> <p>There is also an automated script that will be able to migrate most of your data. Please follow this guide.</p>"},{"location":"importing.html#steps_5","title":"Steps","text":"<ul> <li>Login to your Strong account on the app and go to the \"Settings\" page.</li> <li>Scroll down to the \"General\" section and click on \"Export data\".</li> <li>Send the file to your desktop/laptop and upload it in the input.</li> <li>The mapping section is used to map exercises from Strong to Ryot. Each exercise must be   mapped, otherwise the import will fail.</li> <li>If an exercise does not exist in your instance, you need to create it before mapping it.</li> <li>Once you have mapped all the exercises, click on \"Import\".</li> </ul>"},{"location":"importing.html#trakt","title":"Trakt","text":"<p>All movies and shows can be imported from Trakt along with their ratings, history, comments and lists. A few points to note.</p> <ul> <li>It is necessary to set your account's privacy to public during the   duration of the import. The Trakt authentication flow is pretty complicated   and I don't think it would be worth implementing.</li> <li>Items that have been \"check(ed) in\" will not be imported.</li> </ul>"},{"location":"importing.html#steps_6","title":"Steps","text":"<ul> <li>Login to your Trakt account and go to the settings page.</li> <li>If your account is set to private, uncheck the box next to it. You can revert   this change once the import is complete.</li> <li>If you have any lists that are private, you need to change them to public.   Otherwise they will not be imported.</li> <li>Find your profile slug. This is usually your username. You can find it by   going to your profile page, and checking the URL.</li> <li>Enter this username in the input.</li> </ul>"},{"location":"importing.html#imdb","title":"IMDb","text":"<p>You can import your watchlist from IMDb. They will be added to the \"Watchlist\" collection.</p>"},{"location":"importing.html#steps_7","title":"Steps","text":"<ul> <li>Go to your account and select your watchlist.</li> <li>Go the bottom and click on the \"Export this list\" button.</li> <li>Upload the csv file in the input.</li> </ul>"},{"location":"importing.html#igdb","title":"IGDb","text":"<p>You can import your lists from IGDb. Each list has to be imported separately. A few points to note:</p> <ul> <li>Importing into the \"In Progress\" collection will set 5% progress for the items.</li> <li>Importing into the \"Completed\" collection will set 100% progress for the items.</li> <li>Import into any other collection will just add the items to the collection.</li> </ul>"},{"location":"importing.html#steps_8","title":"Steps","text":"<ul> <li>Login to your account and go to your profile. The default activity lists can be exported   from  here. Click on the list you want to export and download it as CSV.</li> <li>For your custom lists, please visit the \"My Lists\" page.</li> <li>Upload the CSV file and choose the collection you want to import into.</li> </ul>"},{"location":"importing.html#audiobookshelf","title":"Audiobookshelf","text":"<p>The Audiobookshelf importer supports importing all media that have a valid Audible ID or ITunes ID or ISBN.</p> <p>Warning</p> <ul> <li>This will only import media that are already finished. Setup an   integration if you want to import media in progress.</li> <li>If you have enabled the option to auto delete podcast episodes, you'll have to   manually mark them as completed.</li> </ul>"},{"location":"importing.html#steps_9","title":"Steps","text":"<ul> <li>Obtain an API token as described in the Audiobookshelf   authentication docs.</li> <li>Enter the correct details in the input.</li> </ul>"},{"location":"importing.html#tv-time","title":"TV Time","text":"<p>Warning</p> <p>This is a community maintained integration.</p> <p>All shows can be imported from TvTime at the moment using an external tool. You can find all the necessary steps here.</p>"},{"location":"importing.html#open-scale","title":"Open Scale","text":"<p>You can import your measurements from Open Scale app.</p> <p>This can be done by clicking on the three dots on the top right corner of the app, and then clicking on \"Export\". This will save a CSV file to your file system. Upload this file in the input.</p>"},{"location":"importing.html#jellyfin","title":"Jellyfin","text":"<p>You can import your watched movies and shows from Jellyfin.</p> <p>Warning</p> <p>This will only import media that are already finished. Setup an   integration if you want to import media in progress.</p> <p>Enter the correct details in the input. The username you enter should be of the account whose data you want to import.</p>"},{"location":"importing.html#generic-json","title":"Generic Json","text":"<p>The \"Generic Json\" can be used to import all possible data from a generic JSON file. The format of the JSON file should be <code>CompleteExport</code> as described in the exporting documentation.</p> <p>You can use this to export all your data from one Ryot instance and import it into another, or from a source that is not supported by Ryot.</p>"},{"location":"integrations.html","title":"Integrations","text":"<p>Integrations can be used to continuously update your media progress or inform external services about changes. They can be of following types:</p> <ul> <li>Sink: An external client publishes progress updates to the Ryot server.</li> <li>Yank: Progress data is downloaded from an externally running server at a periodic   interval.</li> <li>Push: Ryot sends data to an external service when an event occurs.</li> </ul>"},{"location":"integrations.html#sink-integrations","title":"Sink integrations","text":"<p>These work via webhooks wherein an external service can inform Ryot about a change. All webhook URLs follow this format:</p> <pre><code>https://&lt;instance_url&gt;/backend/_i/&lt;slug&gt;\nhttps://pro.ryot.io/backend/_i/int_a6cGGXEq6KOI # example\n</code></pre> <p>Warning</p> <p>Keep your webhook urls private to prevent abuse.</p>"},{"location":"integrations.html#jellyfin","title":"Jellyfin","text":"<p>Automatically add new Jellyin movie and show plays to Ryot. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <p>Info</p> <p>Requires the unofficial webhook plugin to be installed and active in Jellyfin.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>In the Jellyfin webhook plugin settings, add a new webhook using the    following settings:<ul> <li>Webhook Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> <li>Payload format =&gt; <code>Default</code></li> <li>Listen to events only for =&gt; Choose your user</li> <li>Events =&gt; <code>Play</code>, <code>Pause</code>, <code>Resume</code>, <code>Stop</code> and <code>Progress</code></li> </ul> </li> </ol>"},{"location":"integrations.html#emby","title":"Emby","text":"<p>Automatically add new Emby movie and show plays to Ryot. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>In the Emby notification settings page, add a new notification using the    Webhooks option:<ul> <li>Name =&gt; <code>ryot</code></li> <li>Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> <li>Request Content Type =&gt; <code>application/json</code></li> <li>Events =&gt; <code>Play</code>, <code>Pause</code>, <code>Resume</code>, <code>Stop</code> and <code>Progress</code></li> <li>Limit user events to =&gt; Choose your user</li> </ul> </li> </ol> <p>Warning</p> <p>Since Emby does not send the expected TMDb ID for shows, progress will only be synced if you already have the show in the Ryot database. To do this, simply add the show to your watchlist.</p>"},{"location":"integrations.html#plex","title":"Plex","text":"<p>Automatically add Plex show and movie plays to Ryot. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page using the following settings:<ul> <li>Username =&gt; Your Plex <code>Fullname</code>. If you have no <code>Fullname</code> specified in Plex,    fallback to your Plex <code>Username</code>. This will be used to filter webhooks for the    specified Plex account only.</li> </ul> </li> <li>In your Plex Webhooks settings, add a new webhook using the following settings:<ul> <li>Webhook Url =&gt; <code>&lt;paste_url_copied&gt;</code></li> </ul> </li> </ol> <p>Warning</p> <p>Since Plex does not send the expected TMDb ID for shows, progress will only be synced if you already have the show in the Ryot database. To do this, simply add the show to your watchlist.</p>"},{"location":"integrations.html#kodi","title":"Kodi","text":"<p>The Kodi integration allows syncing the current movie or TV show you are watching. It will work for all the media that have a valid TMDb ID attached to their metadata.</p> <ol> <li>Generate a slug in the integration settings page. Copy the newly generated    webhook Url.</li> <li>Download the addon from github releases.    The file will have a name of <code>script.ryot.zip</code>.</li> <li>Install    the zipped addon to your Kodi instance. Once installed, it will be visible under    the \"Services\" sub category named \"Ryot\".</li> <li>Click on \"Configure\" to fill in the correct details.</li> </ol>"},{"location":"integrations.html#generic-json","title":"Generic Json","text":"<p>The \"Generic Json\" can be used to import all possible data using a generic JSON data format. The format of the JSON file should be <code>CompleteExport</code> as described in the exporting documentation.</p> <p>You can use this to build integrations with other services that Ryot does not support natively.</p>"},{"location":"integrations.html#yank-integrations","title":"Yank integrations","text":"<p>You can configure the interval at which the data is fetched from the external source using the <code>INTEGRATION_SYNC_EVERY_MINUTES</code> environment variable. Defaults to <code>5</code>.</p>"},{"location":"integrations.html#audiobookshelf","title":"Audiobookshelf","text":"<p>Warning</p> <p>This will only import media that are in progress. Perform an   import if you want to import media that are finished.</p> <p>The Audiobookshelf integration can sync all media if they have a valid provider ID (Audible, ITunes or ISBN).</p> <ol> <li>Obtain an API token as described in the Audiobookshelf    authentication docs.</li> <li>Go to your Ryot user settings and add the correct details as described in the    yank section.</li> </ol>"},{"location":"integrations.html#komga","title":"Komga","text":"<p>The Komga integration can sync all media if they have a valid metadata provider.</p>"},{"location":"integrations.html#steps","title":"Steps","text":"<p>If you use Komf or some similar metadata provider these urls will be populated automatically. If you don't, you will either need to manually add the manga to your collection or you can perform the following steps.</p> <ol> <li>Navigate to the manga and open the Edit tab</li> <li>Navigate to the Links tab</li> <li>Create a link named <code>AniList</code> or <code>MyAnimeList</code> providing the respective url (not case-sensitive)</li> </ol> <p>Then perform these steps on Ryot</p> <ol> <li>Create an integration and select Komga as the source</li> <li>Provide your Base URL. It should look something like this <code>http://komga.acme.com</code> or    <code>http://127.0.0.1:25600</code></li> <li>Provide your Username and Password.</li> <li>Provide your preferred metadata provider. Ryot will attempt the others if the preferred    is unavailable and will fallback to title search otherwise.</li> </ol>"},{"location":"integrations.html#push-integrations","title":"Push integrations","text":"<p>You can enable the following push integrations:</p>"},{"location":"integrations.html#radarr","title":"Radarr","text":"<p>Events: <code>Item added to collection</code></p> <ol> <li>Obtain your Radarr API key by going to the Radarr general settings page.</li> <li>Fill the inputs in the integration settings page with the correct details.</li> </ol>"},{"location":"integrations.html#sonarr","title":"Sonarr","text":"<p>Events: <code>Item added to collection</code></p> <ol> <li>Obtain your Sonarr API key by going to the Sonarr general settings page.</li> <li>Fill the inputs in the integration settings page with the correct details.</li> </ol>"},{"location":"integrations.html#jellyfin_1","title":"Jellyfin","text":"<p>Events: <code>Item marked as completed</code></p> <ol> <li>While creating the integration, you will be asked to provide your Jellyfin username and    password.</li> <li>Every time you mark a movie or show as watched in Ryot, the integration will mark it as    watched in Jellyfin.</li> </ol>"},{"location":"migration.html","title":"Migration","text":"<p>All steps below are required unless otherwise stated. Please follow them in the correct order. Please make sure to replace <code>ryot</code> with <code>ryot-pro</code> if you are using the pro version.</p>"},{"location":"migration.html#from-v6-to-v7","title":"From <code>v6.*</code> to <code>v7.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v6.11.0</code> to make sure all <code>v6</code> migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v6.11.0\"</code> in your docker-compose    file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v7.*</code>). For example you can make this    change: <code>image: \"ignisda/ryot:v7\"</code> in your docker-compose file. This will    automatically apply all migrations required for the new version.</p> </li> <li> <p>Login as the admin user and go to the \"Miscellaneous\" settings page and click on the    button to \"Perform background tasks\".</p> </li> </ol>"},{"location":"migration.html#from-v5-to-v6","title":"From <code>v5.*</code> to <code>v6.*</code>","text":"<p>Integrations deleted</p> <p>All integrations need to be recreated. Please take a look at the docs for the new webhook format.</p> <ol> <li> <p>Upgrade the server to <code>v5.5.6</code> to make sure all <code>v5</code> migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v5.5.6\"</code> in your docker-compose    file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v6.*</code>). For example you can make this    change: <code>image: \"ignisda/ryot:latest\"</code> in your docker-compose file. This will    automatically apply all migrations.</p> </li> </ol>"},{"location":"migration.html#from-v4-to-v5","title":"From <code>v4.*</code> to <code>v5.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v4.4.3</code> to make sure all <code>v4</code> migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v4.4.3\"</code> in your docker-compose    file.</p> </li> <li> <p>Create a backup of your database. Here    is a guide on how to do this.</p> </li> <li> <p>Now you can upgrade to the latest version (<code>v5.*</code>). For example you can make this    change: <code>image: \"ignisda/ryot:latest\"</code> in your docker-compose file. This will    automatically apply all migrations.</p> </li> </ol>"},{"location":"migration.html#from-v3-to-v4","title":"From <code>v3.*</code> to <code>v4.*</code>","text":"<p>Webhook URL changes</p> <p>If you were using Plex, Jellyfin or Kodi, all webhooks urls will now have the <code>/backend</code> prefix. Please take a look at the integration docs for the new format.</p> <ol> <li> <p>Upgrade the server to <code>v3.5.4</code> to make sure all pending migrations are applied. For    example, you can make this change: <code>image: \"ignisda/ryot:v3.5.4\"</code> in your docker-compose    file.</p> </li> <li> <p>Go to the \"Preferences\" settings, then the \"General\" tab, and click on \"Disable yank    integrations\" twice. This will ensure that latest preferences have been applied.</p> </li> <li> <p>Go to the \"Miscellaneous\" settings and click on \"Re-evaluate workouts\".</p> </li> <li> <p>Next, click on the button to \"Clean and regenerate\" your summary. This takes time if    you have a lot of media. Go to the dashboard and check the time under the \"Summary\"    section. It should say \"Calculated just now\".</p> </li> <li> <p>Logout and then clear the local storage and cookies for your domain.    Here    is a guide on how to do this. Uninstall the PWA if you have it installed.</p> </li> <li> <p>Create a backup of the database.</p> </li> <li> <p>Connect to the database (<code>docker exec -u postgres -it ryot-db psql</code>) and run these SQL    queries:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230413_create_person', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230501_create_metadata_group', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230504_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230622_create_exercise', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230804_create_user_measurement', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230819_create_workout', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_partial_metadata', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230912_create_calendar_event', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231003_create_partial_metadata_to_person', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231016_create_collection_to_entity', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231017_create_user_to_entity', 1697640078);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest version (<code>v4.*</code>) safely. For example you can make this    change: <code>image: \"ignisda/ryot:latest\"</code> in your docker-compose file.</p> </li> </ol>"},{"location":"migration.html#from-v2-to-v3","title":"From <code>v2.*</code> to <code>v3.*</code>","text":"<ol> <li> <p>Upgrade the server to <code>v2.24.2</code> to make sure all pending migrations are applied.</p> </li> <li> <p>Go to the \"Miscellaneous\" settings and click on the button to \"Clean and regenerate\"    your summary. This takes time if you have a lot of media. Go to the dashboard and check    the time under the \"Summary\" section. It should say \"Calculated just now\".</p> </li> <li> <p>Go to the \"Preferences\" settings, then the \"General\" tab, and click any switch button    twice to make sure the latest settings have been applied.</p> </li> <li> <p>Stop the running server and create a backup of your database.</p> </li> <li> <p>Connect to the database and run these SQL queries:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230413_create_person', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230507_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230622_create_exercise', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230804_create_user_measurement', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230819_create_workout', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_metadata_group', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230901_create_partial_metadata', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230912_create_calendar_event', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231003_create_partial_metadata_to_person', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231016_create_collection_to_entity', 1697640078);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20231017_create_user_to_entity', 1697640078);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest release safely.</p> </li> </ol>"},{"location":"migration.html#from-v1-to-v2","title":"From <code>v1.*</code> to <code>v2.*</code>","text":"<ol> <li> <p>Stop the running server and create a backup of your database.</p> </li> <li> <p>Run the last release of the server to perform all migrations (make sure to connect it to the correct database).    <pre><code>$ docker run --volume ./ryot/data:/data ignisda/ryot:v1.22.1\n</code></pre></p> </li> <li> <p>Once the migrations from the above step are done, stop the server.</p> </li> <li> <p>Before upgrading to the public release, connect to the database again and run these migrations:    <pre><code>DELETE FROM seaql_migrations;\n\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230410_create_metadata', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230412_create_creator', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230417_create_user', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230419_create_seen', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230502_create_genre', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230505_create_review', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230507_create_collection', 1684693316);\nINSERT INTO seaql_migrations (version, applied_at) VALUES ('m20230509_create_import_report', 1684693316);\n</code></pre></p> </li> <li> <p>Now you can upgrade to the latest release safely.</p> </li> <li> <p>OPTIONAL: Once you have the new server up and running, go to the \"Miscellaneous\" settings page and click on the button to \"Update All Metadata\".</p> </li> </ol>"},{"location":"guides/authentication.html","title":"Authentication","text":"<p>Ryot supports multiple authentication methods. By default, it uses local authentication which means that you can log in using a username and password.</p>"},{"location":"guides/authentication.html#openid","title":"OpenID","text":"<p>Ryot can be configured to use OpenID Connect (OIDC) for authentication. The following environment variables need to be set:</p> <pre><code>FRONTEND_URL=https://pro.ryot.io # The URL of your Ryot instance\nSERVER_OIDC_CLIENT_ID=********\nSERVER_OIDC_CLIENT_SECRET=********\nSERVER_OIDC_ISSUER_URL=https://accounts.google.com # The URL of your OIDC provider (might end with trailing slash)\n# Below are optional\nFRONTEND_OIDC_BUTTON_LABEL=Use Google\nRUST_LOG=ryot=debug # To debug why OIDC authentication is failing\n</code></pre> <p>In your OIDC provider, you will need to set the redirect URL to <code>&lt;FRONTEND_URL&gt;/api/auth</code>. The scopes required are <code>openid email</code>.</p> <p>Once these are set, restart your Ryot instance and you should be able to see the button to \"Continue with OpenID Connect\" on the authentication pages. New users will have their username set to their email address. This can be changed later in the profile settings.</p> <p>Warning</p> <p>A user can authenticate using only one provider at a time.</p> <p>You can set <code>USERS_DISABLE_LOCAL_AUTH=true</code> to disable local authentication and only allow users to authenticate using OIDC.</p>"},{"location":"guides/books.html","title":"Books","text":"<p>A guide about books integration for Ryot.</p>"},{"location":"guides/books.html#integration-with-google-books","title":"Integration with Google Books","text":"<p>Ryot also supports tracking books via Google Books. However, the API is heavily rate limited, so it is not possible to hardcode the API keys in the application (unlike the others).</p> <p>You can follow the below steps to obtain your own API keys and enable book tracking with Google Books.</p>"},{"location":"guides/books.html#steps","title":"Steps","text":"<ol> <li> <p>Create a Google Cloud Platform account. Open your Google    Cloud Platform Console.</p> </li> <li> <p>Use the default project or click on \"Create a project\" on the dashboard.</p> </li> <li> <p>Open the APIs &amp; Services Dashboard.</p> </li> <li> <p>Click on \"Enable APIs and Services\". Search for \"Google Books API\" and click on    \"Enable\".</p> </li> <li> <p>Click on \"Credentials\" on the left sidebar. Click on \"Create Credentials\" and select    \"API key\".</p> </li> <li> <p>Click on \"Create\" and copy the API key.</p> </li> <li> <p>Set the <code>BOOKS_GOOGLE_BOOKS_API_KEY</code> environment variable as described in the    configuration docs.</p> </li> </ol>"},{"location":"guides/exporting.html","title":"Exporting","text":"<p>You need to have S3 configured in order to export your data. You can find the necessary configuration parameters under the <code>FileStorageConfig</code> section. The export will be made in JSON format and always follows the schema (<code>CompleteExport</code>) described below.</p> <p>You can export your data from the app by going to the \"Imports and Exports\" settings page and then clicking the button under the \"Export\" tab.</p> <p>Once the export is complete, it will appear along with a button to download it.</p>"},{"location":"guides/exporting.html#one-time-file-storage","title":"One time file storage","text":"<p>If you want to use file storage only for exporting, you can configure it to use a public S3 instance offered by Minio.</p> <p>Not for production use</p> <p>The Minio team resets this instance every 24 hours, hence this method is not suitable if you want to store the data for a long time.</p> <ul> <li>Go to the Minio playground. The username is <code>minioadmin</code> and   password is <code>minioadmin</code>.</li> <li>Click on \"Buckets\" under the \"Administrator\" section and then on \"Create Bucket\".</li> <li>Set a name and click on \"Create Bucket\".</li> <li>Click on \"Access Keys\" under the \"User\" section and then on \"Create access key\".</li> <li>Leave everything as it is and click on \"Create\". Copy both the values displayed.</li> <li>On your Ryot instance, set the following environment variables:     <pre><code>FILE_STORAGE_S3_URL=https://play.min.io\nFILE_STORAGE_S3_BUCKET_NAME=ryot-demo\nFILE_STORAGE_S3_ACCESS_KEY_ID=cqXhVseqa4mpqS4RLG3p\nFILE_STORAGE_S3_SECRET_ACCESS_KEY=sJxF4eZkuc4Eo6daGEFhTctzKzGbY6G6qAQTb8Wy\n</code></pre></li> <li>Restart your Ryot instance and follow the steps described in the previous section.</li> </ul>"},{"location":"guides/exporting.html#exporting-the-entire-database","title":"Exporting the entire database","text":"<p>While debugging, I might ask you to send me a database dump. You can do this by exporting the entire database and emailing the file.</p> <pre><code>docker exec -u postgres -i ryot-db pg_dump -Fc --no-acl --no-owner &gt; /tmp/ryot.file.sql\n</code></pre> <p>To restore the above dump, run the following command:</p> <pre><code>docker exec -u postgres -i ryot-db pg_restore -U postgres -d postgres &lt; /tmp/ryot.file.sql\n</code></pre>"},{"location":"guides/exporting.html#type-definitions","title":"Type definitions","text":"<pre><code>// Automatically generated by schematic. DO NOT MODIFY!\n\n/* eslint-disable */\n\nexport interface IdAndNamedObject {\nid: string;\nname: string;\n}\n\n/** Comments left in replies to posted reviews. */\nexport interface ImportOrExportItemReviewComment {\ncreated_on: string;\nid: string;\n/** The user ids of all those who liked it. */\nliked_by: string[];\ntext: string;\nuser: IdAndNamedObject;\n}\n\nexport type Visibility = 'public' | 'private';\n\n/** Review data associated to a rating. */\nexport interface ImportOrExportItemReview {\n/** The date the review was posted. */\ndate: string | null;\n/** Whether to mark the review as a spoiler. Defaults to false. */\nspoiler: boolean | null;\n/** Actual text for the review. */\ntext: string | null;\n/**\n     * The visibility set by the user.\n     *\n     * @default 'public'\n     */\nvisibility: Visibility | null;\n}\n\n/** A rating given to an entity. */\nexport interface ImportOrExportItemRating {\n/** If for an anime, the episode for which this review was for. */\nanime_episode_number: number | null;\n/** The comments attached to this review. */\ncomments: ImportOrExportItemReviewComment[] | null;\n/** If for a manga, the chapter for which this review was for. */\nmanga_chapter_number: string | null;\n/** If for a podcast, the episode for which this review was for. */\npodcast_episode_number: number | null;\n/** The score of the review. */\nrating: string | null;\n/** Data about the review. */\nreview: ImportOrExportItemReview | null;\n/** If for a show, the episode for which this review was for. */\nshow_episode_number: number | null;\n/** If for a show, the season for which this review was for. */\nshow_season_number: number | null;\n}\n\n/** Details about a specific exercise item that needs to be exported. */\nexport interface ImportOrExportExerciseItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The name of the exercise. */\nname: string;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n}\n\n/** The actual statistics that were logged in a user measurement. */\nexport interface UserMeasurementStats {\nabdominal_skinfold: string | null;\nbasal_metabolic_rate: string | null;\nbiceps_circumference: string | null;\nbody_fat: string | null;\nbody_fat_caliper: string | null;\nbody_mass_index: string | null;\nbone_mass: string | null;\ncalories: string | null;\nchest_circumference: string | null;\nchest_skinfold: string | null;\ncustom: Record&lt;string, string&gt; | null;\nhip_circumference: string | null;\nlean_body_mass: string | null;\nmuscle: string | null;\nneck_circumference: string | null;\nthigh_circumference: string | null;\nthigh_skinfold: string | null;\ntotal_body_water: string | null;\ntotal_daily_energy_expenditure: string | null;\nvisceral_fat: string | null;\nwaist_circumference: string | null;\nwaist_to_height_ratio: string | null;\nwaist_to_hip_ratio: string | null;\nweight: string | null;\n}\n\n/** An export of a measurement taken at a point in time. */\nexport interface UserMeasurement {\n/** Any comment associated entered by the user. */\ncomment: string | null;\n/** The name given to this measurement by the user. */\nname: string | null;\n/** The contents of the actual measurement. */\nstats: UserMeasurementStats;\n/** The date and time this measurement was made. */\ntimestamp: string;\n}\n\n/** The different types of media that can be stored. */\nexport type MediaLot = 'audio_book' | 'anime' | 'book' | 'podcast' | 'manga' | 'movie' | 'show' | 'video_game' | 'visual_novel';\n\n/** A specific instance when an entity was seen. */\nexport interface ImportOrExportMediaItemSeen {\n/** If for an anime, the episode which was seen. */\nanime_episode_number: number | null;\n/** The timestamp when finished watching. */\nended_on: string | null;\n/** If for a manga, the chapter which was seen. */\nmanga_chapter_number: string | null;\n/** If for a manga, the volume which was seen. */\nmanga_volume_number: number | null;\n/** If for a podcast, the episode which was seen. */\npodcast_episode_number: number | null;\n/** The progress of media done. If none, it is considered as done. */\nprogress: string | null;\n/** The provider this item was watched on. */\nprovider_watched_on: string | null;\n/** If for a show, the episode which was seen. */\nshow_episode_number: number | null;\n/** If for a show, the season which was seen. */\nshow_season_number: number | null;\n/** The timestamp when started watching. */\nstarted_on: string | null;\n}\n\n/** The different sources (or providers) from which data can be obtained from. */\nexport type MediaSource = 'anilist' | 'audible' | 'custom' | 'google_books' | 'igdb' | 'itunes' | 'listennotes' | 'manga_updates' | 'mal' | 'openlibrary' | 'tmdb' | 'vndb';\n\n/** Details about a specific media item that needs to be imported or exported. */\nexport interface ImportOrExportMediaItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. For eg: TMDB-ID, Openlibrary ID and so on. */\nidentifier: string;\n/**\n     * The type of media.\n     *\n     * @default 'book'\n     * @type {'audio_book' | 'anime' | 'book' | 'podcast' | 'manga' | 'movie' | 'show' | 'video_game' | 'visual_novel'}\n     */\nlot: MediaLot;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/** The seen history for the user. */\nseen_history: ImportOrExportMediaItemSeen[];\n/**\n     * The source of media.\n     *\n     * @default 'audible'\n     * @type {'anilist' | 'audible' | 'custom' | 'google_books' | 'igdb' | 'itunes' | 'listennotes' | 'manga_updates' | 'mal' | 'openlibrary' | 'tmdb' | 'vndb'}\n     */\nsource: MediaSource;\n/** An string to help identify it in the original source. */\nsource_id: string;\n}\n\n/** Details about a specific media group item that needs to be imported or exported. */\nexport interface ImportOrExportMediaGroupItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. For eg: TMDB-ID, Openlibrary ID and so on. */\nidentifier: string;\n/**\n     * The type of media.\n     *\n     * @default 'book'\n     * @type {'audio_book' | 'anime' | 'book' | 'podcast' | 'manga' | 'movie' | 'show' | 'video_game' | 'visual_novel'}\n     */\nlot: MediaLot;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/**\n     * The source of media.\n     *\n     * @default 'audible'\n     * @type {'anilist' | 'audible' | 'custom' | 'google_books' | 'igdb' | 'itunes' | 'listennotes' | 'manga_updates' | 'mal' | 'openlibrary' | 'tmdb' | 'vndb'}\n     */\nsource: MediaSource;\n/** Name of the group. */\ntitle: string;\n}\n\nexport interface PersonSourceSpecifics {\nis_anilist_studio: boolean | null;\nis_tmdb_company: boolean | null;\n}\n\n/** Details about a specific creator item that needs to be exported. */\nexport interface ImportOrExportPersonItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The provider identifier. */\nidentifier: string;\n/** The name of the creator. */\nname: string;\n/** The review history for the user. */\nreviews: ImportOrExportItemRating[];\n/**\n     * The source of data.\n     *\n     * @default 'audible'\n     * @type {'anilist' | 'audible' | 'custom' | 'google_books' | 'igdb' | 'itunes' | 'listennotes' | 'manga_updates' | 'mal' | 'openlibrary' | 'tmdb' | 'vndb'}\n     */\nsource: MediaSource;\n/** The source specific data. */\nsource_specifics: PersonSourceSpecifics | null;\n}\n\n/** The assets that were uploaded for an entity. */\nexport interface EntityAssets {\n/** The keys of the S3 images. */\nimages: string[];\n/** The keys of the S3 videos. */\nvideos: string[];\n}\n\n/** The different types of exercises that can be done. */\nexport type ExerciseLot = 'duration' | 'distance_and_duration' | 'reps' | 'reps_and_weight';\n\n/** The types of set (mostly characterized by exertion level). */\nexport type SetLot = 'normal' | 'warm_up' | 'drop' | 'failure';\n\n/** The different types of personal bests that can be achieved on a set. */\nexport type WorkoutSetPersonalBest = 'weight' | 'one_rm' | 'volume' | 'time' | 'pace' | 'reps';\n\n/** Details about the statistics of the set performed. */\nexport interface WorkoutSetStatistic {\ndistance: string | null;\nduration: string | null;\none_rm: string | null;\npace: string | null;\nreps: string | null;\nvolume: string | null;\nweight: string | null;\n}\n\nexport interface WorkoutSetTotals {\nweight: string | null;\n}\n\n/** Details about the set performed. */\nexport interface WorkoutSetRecord {\nactual_rest_time: number | null;\nconfirmed_at: string | null;\n/** @type {'normal' | 'warm_up' | 'drop' | 'failure'} */\nlot: SetLot;\nnote: string | null;\npersonal_bests: WorkoutSetPersonalBest[] | null;\nrest_time: number | null;\nstatistic: WorkoutSetStatistic;\ntotals: WorkoutSetTotals | null;\n}\n\n/** The totals of a workout and the different bests achieved. */\nexport interface WorkoutOrExerciseTotals {\ndistance: string;\nduration: string;\n/** The number of personal bests achieved. */\npersonal_bests_achieved: number;\nreps: string;\n/** The total seconds that were logged in the rest timer. */\nrest_time?: number;\nweight: string;\n}\n\n/** An exercise that has been processed and committed to the database. */\nexport interface ProcessedExercise {\nassets: EntityAssets | null;\n/** @type {'duration' | 'distance_and_duration' | 'reps' | 'reps_and_weight'} */\nlot: ExerciseLot;\nname: string;\nnotes: string[];\nsets: WorkoutSetRecord[];\ntotal: WorkoutOrExerciseTotals | null;\n}\n\nexport interface WorkoutSupersetsInformation {\n/** A color that will be displayed on the frontend. */\ncolor: string;\n/** The identifier of all the exercises which are in the same superset */\nexercises: number[];\n}\n\n/** Information about a workout done. */\nexport interface WorkoutInformation {\nassets: EntityAssets | null;\ncomment: string | null;\nexercises: ProcessedExercise[];\nsupersets: WorkoutSupersetsInformation[];\n}\n\n/** The summary about an exercise done in a workout. */\nexport interface WorkoutSummaryExercise {\nbest_set: WorkoutSetRecord | null;\nlot: ExerciseLot | null;\nname: string;\nnum_sets: number;\n}\n\nexport interface WorkoutSummary {\nexercises: WorkoutSummaryExercise[];\ntotal: WorkoutOrExerciseTotals | null;\n}\n\nexport interface WorkoutTemplate {\ncreated_on: string;\nid: string;\ninformation: WorkoutInformation;\nname: string;\nsummary: WorkoutSummary;\n/**\n     * @default 'public'\n     * @type {'public' | 'private'}\n     */\nvisibility: Visibility;\n}\n\nexport interface ImportOrExportWorkoutTemplateItem {\ncollections: string[];\ndetails: WorkoutTemplate;\n}\n\n/** A workout that was completed by the user. */\nexport interface Workout {\nduration: number;\nend_time: string;\nid: string;\ninformation: WorkoutInformation;\nname: string;\nstart_time: string;\nsummary: WorkoutSummary;\ntemplate_id: string | null;\n}\n\n/** Details about a specific exercise item that needs to be exported. */\nexport interface ImportOrExportWorkoutItem {\n/** The collections this entity was added to. */\ncollections: string[];\n/** The details of the workout. */\ndetails: Workout;\n}\n\n/** Complete export of the user. */\nexport interface CompleteExport {\n/** Data about user's exercises. */\nexercises: ImportOrExportExerciseItem[] | null;\n/** Data about user's measurements. */\nmeasurements: UserMeasurement[] | null;\n/** Data about user's media. */\nmedia: ImportOrExportMediaItem[] | null;\n/** Data about user's media groups. */\nmedia_groups: ImportOrExportMediaGroupItem[] | null;\n/** Data about user's people. */\npeople: ImportOrExportPersonItem[] | null;\n/** Data about user's workout templates. */\nworkout_templates: ImportOrExportWorkoutTemplateItem[] | null;\n/** Data about user's workouts. */\nworkouts: ImportOrExportWorkoutItem[] | null;\n}\n</code></pre>"},{"location":"guides/video-games.html","title":"Video games","text":"<p>A guide about video games integration for Ryot.</p>"},{"location":"guides/video-games.html#integration-with-igdb","title":"Integration with IGDB","text":"<p>Ryot supports tracking video games via IGDB. However, the API is heavily rate limited, so it is not possible to hardcode the API keys in the application (unlike the others).</p> <p>You can follow the below steps to obtain your own API keys and enable video game tracking.</p>"},{"location":"guides/video-games.html#steps","title":"Steps","text":"<ol> <li> <p>Create a Twitch account.</p> </li> <li> <p>Open your developer console.</p> </li> <li> <p>Click on \"Register Your Application\" on the dashboard.</p> </li> <li> <p>Fill up the details. Any name will suffice but it must be unique. Click on \"Create\"    when you are done.</p> </li> <li> <p>You will be guided back to your application dashboard. Click on \"Manage\" for    the application you just created.</p> </li> <li> <p>Generate a client secret. Copy the Client ID and Client Secret.</p> </li> <li> <p>Set the <code>VIDEO_GAMES_*</code> environment variables as described in the    configuration docs.</p> </li> </ol>"}]}